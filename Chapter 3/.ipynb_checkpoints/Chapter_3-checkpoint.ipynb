{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing spaCy in virtualenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-dcb3e51454cc>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-dcb3e51454cc>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    virtualenv env\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "virtualenv env\n",
    "source env/bin/activate\n",
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out-of-the-box: download best-matching default model\n",
    "spacy download en # english model\n",
    "spacy download de # german model\n",
    "spacy download es # spanish model\n",
    "spacy download fr # french model\n",
    "spacy download xx # multi-language model\n",
    "# download best-matching version of specific model for your spaCy installation\n",
    "spacy download en_core_web_sm\n",
    "# download exact model version (doesn't create shortcut link)\n",
    "spacy download en_core_web_sm-2.0.0 --direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using pip to install models\n",
    "pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_md-1.2.0/en_core_web_md-1.2.0.tar.gz\n",
    "# with local file\n",
    "pip install /Users/you/en_core_web_md-1.2.0.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using spaCy\n",
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'This is a sentence.')\n",
    "\n",
    "# Using particular model\n",
    "\n",
    "import en_core_web_md\n",
    "nlp = en_core_web_md.load()\n",
    "doc = nlp(u'This is a sentence.')\n",
    "\n",
    "# Constructing tokenizer\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "nlp.tokenizer = my_tokenizer\n",
    "\n",
    "# printing POS\n",
    "\n",
    "doc = nlp(u'John and I went to the parkâ€™')\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_)\n",
    "\n",
    "# printing NER\n",
    "\n",
    "doc = nlp(u'Microsoft has offices all over Europe.')\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "\n",
    "# Adding stop words\n",
    "\n",
    "my_stop_words = [u'say', u'be', u'said', u'says', u'saying']\n",
    "for stopword in my_stop_words:\n",
    "    lexeme = nlp.vocab[stopword]\n",
    "    lexeme.is_stop = True\n",
    "\n",
    "# pre-processing text\n",
    "\n",
    "doc = nlp(u'The horse galloped down the field and past the river.')\n",
    "sentence = []\n",
    "for w in doc:\n",
    "    # if it's not a stop word or punctuation mark, add it to our article!\n",
    "    if w.text != '\\n' and not w.is_stop and not w.is_punct and not w.like_num:\n",
    "        # we add the lematized version of the word\n",
    "        sentence.append(w.lemma_)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
